"""
RAG Pipeline –¥–ª—è BE –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
Retrieval Augmented Generation —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∑–Ω–∞–Ω–∏–µ–≤–æ–π –±–∞–∑—ã
"""

import logging
import json
from typing import Dict, List, Optional, Tuple

try:
    from langchain_core.documents import Document
except ImportError:
    try:
        from langchain.schema import Document
    except ImportError:
        Document = None

logger = logging.getLogger(__name__)


class RAGPipeline:
    """
    RAG Pipeline –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –¥–∏–∑–∞–π–Ω—É BE –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ LLM –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    """
    
    _instance = None  # –î–ª—è singleton pattern
    
    def __new__(cls, *args, **kwargs):
        """Singleton pattern - –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä"""
        if cls._instance is None:
            cls._instance = super(RAGPipeline, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(
        self,
        vector_store=None,
        llm=None,
        retrieval_mode: str = "hybrid"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG Pipeline
        
        Args:
            vector_store: VectorStore –æ–±—ä–µ–∫—Ç
            llm: LLM –æ–±—ä–µ–∫—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            retrieval_mode: "hybrid" –∏–ª–∏ "pure_retrieval"
        """
        if self._initialized:
            return
        
        self.vector_store = vector_store
        self.llm = llm
        self.retrieval_mode = retrieval_mode
        
        logger.info(f"RAG Pipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (mode: {retrieval_mode})")
        self._initialized = True
    
    def retrieve_context(
        self,
        query: str,
        k: int = 5,
        score_threshold: Optional[float] = None
    ) -> str:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            score_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        
        Returns:
            str: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        if self.vector_store is None:
            logger.warning("Vector store –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return ""
        
        logger.info(f"üîç Retrieve: '{query}'")
        
        results = self.vector_store.search(query, k=k, score_threshold=score_threshold)
        
        if not results:
            logger.warning("‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return ""
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_parts = []
        for i, (doc, score) in enumerate(results, 1):
            source = doc.metadata.get('source', 'Unknown')
            doc_type = doc.metadata.get('type', 'document')
            priority = doc.metadata.get('priority', 5)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ similarity)
            similarity = 1 - score
            
            context_parts.append(f"""
[–ò—Å—Ç–æ—á–Ω–∏–∫ {i}: {doc_type.upper()} | {source}]
[–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.1%} | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}]

{doc.page_content}
""")
        
        context = "\n".join(context_parts)
        logger.info(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        return context
    
    def get_design_recommendation(
        self,
        inn: str,
        cvintra: Optional[float] = None,
        administration_mode: str = "fasted"
    ) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ –¥–∏–∑–∞–π–Ω—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ CVintra
        
        Args:
            inn: –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞
            cvintra: Coefficient of Variation (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–∞)
            administration_mode: "fasted", "fed", –∏–ª–∏ "both"
        
        Returns:
            Dict —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –¥–∏–∑–∞–π–Ω—É
        """
        logger.info(f"üî¨ Design recommendation –¥–ª—è {inn} (CVintra: {cvintra}%)")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ –∑–Ω–∞–Ω–∏–µ–≤–æ–π –±–∞–∑–µ
        query = f"""
        –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∏–∑–∞–π–Ω—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –±–∏–æ—ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞
        —Å –≤–Ω—É—Ç—Ä–∏—Å—É–±—ä–µ–∫—Ç–Ω–æ–π –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å—é CVintra {cvintra}%
        –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ {administration_mode}
        """
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = self.retrieve_context(query, k=5)
        
        # –ë–∞–∑–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ CVintra
        recommendation = self._get_cvintra_based_recommendation(cvintra, administration_mode)
        
        # Augment —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –µ—Å–ª–∏ –µ—Å—Ç—å LLM
        if self.llm and context:
            recommendation = self._augment_with_llm(recommendation, context, inn)
        
        recommendation['context_used'] = context
        return recommendation
    
    def _get_cvintra_based_recommendation(
        self,
        cvintra: Optional[float],
        administration_mode: str
    ) -> Dict:
        """
        –ë–∞–∑–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–Ω–∞—á–µ–Ω–∏—è CVintra
        (–±–µ–∑ LLM, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞)
        """
        if cvintra is None:
            cvintra = 25  # Default –∑–Ω–∞—á–µ–Ω–∏–µ
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∑–∞–π–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ CVintra
        if cvintra <= 20:
            design = "2x2 Crossover"
            sample_size_base = 12
            rationale = f"CVintra ‚â§ 20%: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π 2x2 crossover –¥–∏–∑–∞–π–Ω –¥–æ—Å—Ç–∞—Ç–æ—á–µ–Ω"
            complexity = "low"
        elif cvintra <= 30:
            design = "2x2 Crossover –∏–ª–∏ 2x4 Crossover"
            sample_size_base = 32
            rationale = f"CVintra 21-30%: –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏"
            complexity = "medium"
        else:
            design = "2x2/2x4 Crossover –∏–ª–∏ Parallel"
            sample_size_base = 60
            rationale = f"CVintra > 30%: –≤—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å, —Ç—Ä–µ–±—É–µ—Ç —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è"
            complexity = "high"
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è fed —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if administration_mode == "both":
            sample_size_base = int(sample_size_base * 1.5)
            note = "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (fasted –∏ fed)"
        else:
            note = ""
        
        # –î–æ–±–∞–≤–ª—è–µ–º dropout –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç (15%)
        final_sample_size = int(sample_size_base * 1.15)
        
        return {
            "recommended_design": design,
            "rationale": rationale,
            "cvintra_range": f"{cvintra:.1f}%",
            "administration_mode": administration_mode,
            "sample_size_base": sample_size_base,
            "dropout_rate": 0.15,
            "final_sample_size": final_sample_size,
            "washout_min_periods": 5,
            "complexity": complexity,
            "note": note,
            "regulatory_basis": [
                "–†–µ—à–µ–Ω–∏–µ ‚Ññ 85 –ï–≤—Ä–ê–∑–≠–°",
                "ICH-GCP Guidelines",
                "EMA Bioequivalence Guidance"
            ]
        }
    
    def _augment_with_llm(
        self,
        base_recommendation: Dict,
        context: str,
        inn: str
    ) -> Dict:
        """
        –î–æ–ø–æ–ª–Ω–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é —á–µ—Ä–µ–∑ LLM —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        """
        if not self.llm:
            return base_recommendation
        
        logger.info("üìö Augment with LLM")
        
        prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, 
—É—Ç–æ—á–Ω–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ –¥–∏–∑–∞–π–Ω—É BE –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ {inn}.

–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ë–ê–ó –ó–ù–ê–ù–ò–ô:
{context}

–¢–ï–ö–£–©–ê–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:
{json.dumps(base_recommendation, ensure_ascii=False, indent=2)}

–£—Ç–æ—á–Ω–∏ –∏ —Ä–∞—Å—à–∏—Ä—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é, —É—á–∏—Ç—ã–≤–∞—è:
1. –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —Ä–µ–≥—É–ª—è—Ç–æ—Ä–∞
2. –ü—Ä–∏–º–µ—Ä—ã –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤
3. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å —Ç–µ–º–∏ –∂–µ –∫–ª—é—á–∞–º–∏, –Ω–æ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º.
"""
        
        try:
            response = self.llm.generate(prompt)
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                augmented = json.loads(json_match.group())
                augmented['context_used'] = context
                logger.info("‚úì LLM augmentation successful")
                return augmented
        except Exception as e:
            logger.warning(f"LLM augmentation failed: {str(e)}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è")
        
        return base_recommendation
    
    def get_regulatory_requirements(self, country: str = "russia") -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã
        
        Args:
            country: "russia", "eu", –∏–ª–∏ "us"
        
        Returns:
            Dict —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏
        """
        query = f"–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è {country} –¥–ª—è –±–∏–æ—ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç–∏"
        
        context = self.retrieve_context(query, k=3)
        
        return {
            "country": country,
            "context": context,
            "sources_used": "Knowledge Base"
        }
    
    def format_synopsis_context(self, study_parameters: Dict) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω–æ–ø—Å–∏—Å–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
        
        Args:
            study_parameters: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        
        Returns:
            str: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        """
        inn = study_parameters.get('inn', 'Unknown')
        cvintra = study_parameters.get('cvintra', 25)
        
        query = f"–ü—Ä–∏–º–µ—Ä –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ BE –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è {inn} —Å CVintra {cvintra}%"
        
        context = self.retrieve_context(query, k=3)
        
        return f"""
–ü–†–ò–ú–ï–†–´ –ü–†–û–¢–û–ö–û–õ–û–í –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:
{context}

–ü–ê–†–ê–ú–ï–¢–†–´ –¢–ï–ö–£–©–ï–ì–û –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:
{json.dumps(study_parameters, ensure_ascii=False, indent=2)}
"""
    
    def is_ready(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ RAG pipeline"""
        return (self.vector_store is not None and 
                self.vector_store.is_loaded())
